{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating Datasest from Kaggle Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import os\n",
    "from sklearn.model_selection import train_test_split\n",
    "import shutil"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating low resolution images from Face Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_dir = \"/Users/kavian/Desktop/data/high_resolution_images\"\n",
    "output_dir = \"/Users/kavian/Desktop/data/low_resolution_images\"\n",
    "scale_factor = 0.5  # Adjust this to set the desired low-resolution scale factor\n",
    "\n",
    "if not os.path.exists(output_dir):\n",
    "    os.makedirs(output_dir)\n",
    "\n",
    "for filename in os.listdir(input_dir):\n",
    "    if filename.endswith(\".jpg\") or filename.endswith(\".png\") or filename.endswith(\".gif\") :\n",
    "        img = Image.open(os.path.join(input_dir, filename))\n",
    "        low_res_img = img.resize((int(img.width * scale_factor), int(img.height * scale_factor)), Image.LANCZOS)\n",
    "        low_res_img.save(os.path.join(output_dir, filename))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split Dataset to train, validation and test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_dataset(source_dir, train_dir, test_dir, validation_dir, split_ratio=(0.8, 0.1, 0.1)):\n",
    "    # Get the list of image filenames\n",
    "    file_list = os.listdir(source_dir)\n",
    "    train_files, test_files = train_test_split(file_list, test_size=split_ratio[1] + split_ratio[2], random_state=42)\n",
    "    test_files, validation_files = train_test_split(test_files, test_size=split_ratio[2] / (split_ratio[1] + split_ratio[2]), random_state=42)\n",
    "\n",
    "    # Create the directories if they don't exist\n",
    "    os.makedirs(train_dir, exist_ok=True)\n",
    "    os.makedirs(test_dir, exist_ok=True)\n",
    "    os.makedirs(validation_dir, exist_ok=True)\n",
    "\n",
    "    # Copy images to their respective directories\n",
    "    for filename in train_files:\n",
    "        shutil.copy(os.path.join(source_dir, filename), os.path.join(train_dir, filename))\n",
    "    for filename in test_files:\n",
    "        shutil.copy(os.path.join(source_dir, filename), os.path.join(test_dir, filename))\n",
    "    for filename in validation_files:\n",
    "        shutil.copy(os.path.join(source_dir, filename), os.path.join(validation_dir, filename))\n",
    "\n",
    "source_dir = \"/Users/kavian/Desktop/data/low_resolution_images\"\n",
    "train_dir = \"/Users/kavian/Desktop/data/train/low_resolution\"\n",
    "test_dir = \"/Users/kavian/Desktop/data/test/low_resolution\"\n",
    "validation_dir = \"/Users/kavian/Desktop/data/validation/low_resolution\"\n",
    "split_dataset(source_dir, train_dir, test_dir, validation_dir)\n",
    "\n",
    "source_dir = \"/Users/kavian/Desktop/data/high_resolution_images\"  # Directory with high-resolution images\n",
    "train_dir = \"/Users/kavian/Desktop/data/train/high_resolution\"\n",
    "test_dir = \"/Users/kavian/Desktop/data/test/high_resolution\"\n",
    "validation_dir = \"/Users/kavian/Desktop/data/validation/high_resolution\"\n",
    "split_dataset(source_dir, train_dir, test_dir, validation_dir)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split High Resolution Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "import random\n",
    "import os\n",
    "import shutil\n",
    "\n",
    "def create_subdirectories(root_dir, subdirs):\n",
    "    for subdir in subdirs:\n",
    "        os.makedirs(os.path.join(root_dir, subdir), exist_ok=True)\n",
    "\n",
    "def split_dataset(low_resolution_source_dir, high_resolution_source_dir, train_dir, test_dir, validation_dir, split_ratio=(0.8, 0.1, 0.1), random_seed=42):\n",
    "    # Get the list of low-resolution image filenames and sort them for consistency\n",
    "    low_resolution_file_list = os.listdir(low_resolution_source_dir)\n",
    "    low_resolution_file_list.sort()\n",
    "\n",
    "    # Get the list of high-resolution image filenames and sort them for consistency\n",
    "    high_resolution_file_list = os.listdir(high_resolution_source_dir)\n",
    "    high_resolution_file_list.sort()\n",
    "\n",
    "    # Shuffle both lists with a fixed random seed\n",
    "    random.seed(random_seed)\n",
    "    random.shuffle(low_resolution_file_list)\n",
    "    random.seed(random_seed)\n",
    "    random.shuffle(high_resolution_file_list)\n",
    "\n",
    "    # Split the file lists into training, test, and validation sets\n",
    "    train_files_low_res, test_files_low_res = train_test_split(low_resolution_file_list, test_size=split_ratio[1] + split_ratio[2], random_state=random_seed)\n",
    "    test_files_low_res, validation_files_low_res = train_test_split(test_files_low_res, test_size=split_ratio[2] / (split_ratio[1] + split_ratio[2]), random_state=random_seed)\n",
    "\n",
    "    # Create the directories for train, test, and validation\n",
    "    create_subdirectories(train_dir, [\"high_resolution\", \"low_resolution\"])\n",
    "    create_subdirectories(test_dir, [\"high_resolution\", \"low_resolution\"])\n",
    "    create_subdirectories(validation_dir, [\"high_resolution\", \"low_resolution\"])\n",
    "\n",
    "    # Copy low-resolution images to their respective directories\n",
    "    for filename in train_files_low_res:\n",
    "        shutil.copy(os.path.join(low_resolution_source_dir, filename), os.path.join(train_dir, \"low_resolution\", filename))\n",
    "    for filename in test_files_low_res:\n",
    "        shutil.copy(os.path.join(low_resolution_source_dir, filename), os.path.join(test_dir, \"low_resolution\", filename))\n",
    "    for filename in validation_files_low_res:\n",
    "        shutil.copy(os.path.join(low_resolution_source_dir, filename), os.path.join(validation_dir, \"low_resolution\", filename))\n",
    "\n",
    "    # Split the file lists for high-resolution images using the same random seed\n",
    "    train_files_high_res = [filename for filename in high_resolution_file_list if filename in train_files_low_res]\n",
    "    test_files_high_res = [filename for filename in high_resolution_file_list if filename in test_files_low_res]\n",
    "    validation_files_high_res = [filename for filename in high_resolution_file_list if filename in validation_files_low_res]\n",
    "\n",
    "    # Copy high-resolution images to their respective directories\n",
    "    for filename in train_files_high_res:\n",
    "        shutil.copy(os.path.join(high_resolution_source_dir, filename), os.path.join(train_dir, \"high_resolution\", filename))\n",
    "    for filename in test_files_high_res:\n",
    "        shutil.copy(os.path.join(high_resolution_source_dir, filename), os.path.join(test_dir, \"high_resolution\", filename))\n",
    "    for filename in validation_files_high_res:\n",
    "        shutil.copy(os.path.join(high_resolution_source_dir, filename), os.path.join(validation_dir, \"high_resolution\", filename))\n",
    "\n",
    "# Set the random seed for reproducibility\n",
    "random_seed = 42\n",
    "\n",
    "low_resolution_source_dir = \"/Users/kavian/Desktop/data/low_resolution_images\"\n",
    "high_resolution_source_dir = \"/Users/kavian/Desktop/data/high_resolution_images\"\n",
    "train_dir = \"/Users/kavian/Desktop/data/train\"\n",
    "test_dir = \"/Users/kavian/Desktop/data/test\"\n",
    "validation_dir = \"/Users/kavian/Desktop/data/validation\"\n",
    "split_dataset(low_resolution_source_dir, high_resolution_source_dir, train_dir, test_dir, validation_dir, random_seed=random_seed)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tensorflow_cpu",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
